{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7fa992d8",
      "metadata": {},
      "source": [
        "# Pre-training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f66ff61",
      "metadata": {},
      "source": [
        "As in (Harsuko and Alkhalifah, 2022), pre-training of StorSeismic was intended to make the network learn the \"features\" of a seismic data. In this notebook, we will use the masked seismic data as the input and train the network to reconstruct the masked traces. The backbone of the network is BERT architecture (Devlin et al., 2018), obtained from HuggingFace's <code>transformers</code> library (https://github.com/huggingface/transformers)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6359f787",
      "metadata": {},
      "source": [
        "## Load required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3067be79",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BertConfig, BertForMaskedLM\n",
        "import transformers\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import AutoMinorLocator\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import time\n",
        "from radam import RAdam\n",
        "import sys\n",
        "import pandas as pd\n",
        "import itertools\n",
        "\n",
        "from storseismic.modules import *\n",
        "from storseismic.train import run_pretraining\n",
        "from storseismic.utils import *\n",
        "\n",
        "from storseismic.utils import SSDataset\n",
        "from torch.serialization import add_safe_globals\n",
        "\n",
        "from storseismic.modules import PositionalEncoding\n",
        "from transformers.models.bert.modeling_bert import BertForMaskedLM, BertModel, BertEmbeddings\n",
        "from torch.nn.modules.linear import Linear\n",
        "# Add these imports at the top with other imports\n",
        "from torch.nn import Dropout, LayerNorm\n",
        "\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "params = {\n",
        "    'savefig.dpi': 600,  # to adjust notebook inline plot size\n",
        "    'figure.dpi' : 600,\n",
        "    'axes.labelsize':14,  # fontsize for x and y labels (was 10)\n",
        "    'axes.titlesize':14,\n",
        "    'axes.titleweight': 'bold',\n",
        "    'legend.fontsize': 14,  # was 10\n",
        "    'xtick.labelsize':12,\n",
        "    'ytick.labelsize':12,\n",
        "    'font.family': 'serif',\n",
        "}\n",
        "matplotlib.rcParams.update(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8b5548b",
      "metadata": {},
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc8b64c1",
      "metadata": {},
      "source": [
        "### Pre-training configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5b28675",
      "metadata": {},
      "outputs": [],
      "source": [
        "config = BertConfig()\n",
        "\n",
        "# Model Parameter\n",
        "config.hidden_size = 256\n",
        "config.num_hidden_layers = 4\n",
        "config.num_attention_heads = 4\n",
        "config.num_hidden_ffn = 4\n",
        "config.attention_type = \"default\"\n",
        "config.k = 20\n",
        "config.fixed = False\n",
        "config.add_alibi = False # Add Linear Bias option (https://arxiv.org/abs/2108.12409)\n",
        "config.alibi_type = \"nosym\"\n",
        "config.fixed_slopes = False\n",
        "config.add_urpe = False # Add Universal Relative Positional Encoding (https://arxiv.org/abs/2205.13401)\n",
        "\n",
        "config.vocab_size = 256 # Time samples\n",
        "config.intermediate_size = config.hidden_size*config.num_hidden_ffn\n",
        "config.max_length = 20 # Offsets\n",
        "config.max_position_embeddings = config.max_length\n",
        "config.position_embedding_type = 'sincos'\n",
        "config.input_type = 'trace'\n",
        "config.embedding_type = 'none'\n",
        "config.type_vocab_size = 2\n",
        "config.output_hidden_states = True\n",
        "config.output_attentions = True\n",
        "config.output_scores = True\n",
        "# Toggle Pre-LN BERT\n",
        "config.pre_ln = True # True, False\n",
        "\n",
        "# Training Parameter\n",
        "config.batch_size = 10\n",
        "config.lr = 5e-4\n",
        "config.epoch = 1000\n",
        "config.patience = 20\n",
        "\n",
        "# I/O parameter\n",
        "config.parent_dir = './results/pretrain/'\n",
        "config.dataset = './data/pretrain/'\n",
        "\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd79b009",
      "metadata": {},
      "source": [
        "### Load data and wrap in Pytorch DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "626e90f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add SSDataset to the safe globals list\n",
        "add_safe_globals([SSDataset])\n",
        "\n",
        "train_data = torch.load(os.path.join(config.dataset, 'train_data.pt'))\n",
        "test_data = torch.load(os.path.join(config.dataset, 'test_data.pt'))\n",
        "\n",
        "vmin_all = -1\n",
        "vmax_all = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c6d9dd7",
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = config.batch_size\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for i, X in enumerate(train_dataloader):\n",
        "    if i == 0:\n",
        "        for j in range(4):\n",
        "            f, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "            ax[0].imshow(X['inputs_embeds'][j, :, :].swapaxes(0, 1) - X['inputs_embeds'][j, :, :].mean(), \n",
        "                         aspect=1, vmin=vmin_all, vmax=vmax_all, cmap='seismic')\n",
        "            ax[0].set_title(\"Input\")\n",
        "            ax[1].imshow(X['labels'][j, :, :].swapaxes(0, 1) - X['labels'][j, :, :].mean(), \n",
        "                         aspect=1, vmin=vmin_all, vmax=vmax_all, cmap='seismic')\n",
        "            ax[1].set_title(\"Label\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eea5e9a",
      "metadata": {},
      "source": [
        "## Setup StorSeismic pre-training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d4b8e50",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.exists(config.parent_dir):\n",
        "    os.makedirs(config.parent_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9514a4e",
      "metadata": {},
      "source": [
        "### Swap built-in modules with the pre-defined ones"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a921e17",
      "metadata": {},
      "source": [
        "#### Swap the embedding and the prediction head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8f42cc3",
      "metadata": {},
      "outputs": [],
      "source": [
        "transformers.models.bert.modeling_bert.BertEmbeddings = BertEmbeddings\n",
        "transformers.models.bert.modeling_bert.BertOnlyMLMHead = BertOnlyMLMHead\n",
        "transformers.models.bert.modeling_bert.BertSelfAttention = BertSelfAttention"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ec8e21d",
      "metadata": {},
      "source": [
        "#### Check existing starting model before changing other modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a43b599",
      "metadata": {},
      "outputs": [],
      "source": [
        "starting_model_fn = ('_').join([str(config.hidden_size), str(config.num_hidden_layers), \"startingmodel.pt\"])\n",
        "if not os.path.exists(os.path.join(config.parent_dir, \"starting_model\")):\n",
        "    os.makedirs(os.path.join(config.parent_dir, \"starting_model\"))\n",
        "if not os.path.exists(os.path.join(config.parent_dir, \"starting_model\", starting_model_fn)):\n",
        "    model = BertForMaskedLM(config)\n",
        "    torch.save(model, os.path.join(config.parent_dir, \"starting_model\", starting_model_fn))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85dd9c1e",
      "metadata": {},
      "source": [
        "#### Swap with Pre-LN or Post-LN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c67f1d20",
      "metadata": {},
      "source": [
        "We will use Pre-LN BERT instead of Post-LN BERT, which is more insensitive to hyperparameter tuning (Xiong et al., 2020)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e294df10",
      "metadata": {},
      "outputs": [],
      "source": [
        "if config.pre_ln:\n",
        "    transformers.models.bert.modeling_bert.BertSelfOutput = PreLNBertSelfOutput\n",
        "    transformers.models.bert.modeling_bert.BertAttention = PreLNBertAttention\n",
        "    transformers.models.bert.modeling_bert.BertIntermediate = PreLNBertIntermediate\n",
        "    transformers.models.bert.modeling_bert.BertOutput = PreLNBertOutput"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9a6395c",
      "metadata": {},
      "source": [
        "### Instantiate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9641c7ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = BertForMaskedLM(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e47e3e98",
      "metadata": {},
      "source": [
        "#### Load weights from starting model (to preserve starting point on every run)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01bffdd2",
      "metadata": {},
      "source": [
        "#### Check number of trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b0f1350",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5381d67",
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    table = pd.DataFrame(columns=['Name', 'Parameter'])\n",
        "    total_params = 0\n",
        "    i = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        total_params+=param\n",
        "        table.loc[i] = [name] + [param]\n",
        "        i += 1\n",
        "    display(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "    \n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "869780d8",
      "metadata": {},
      "source": [
        "#### Send model to device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "832c5999",
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "print(\"Using device: {}\".format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0af1ca9",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7926c577",
      "metadata": {},
      "source": [
        "### Set up training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff7fc0de",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create projection layer to convert from vocab_size (271) to hidden_size (256)\n",
        "projection = nn.Linear(config.vocab_size, config.hidden_size).to(device)\n",
        "\n",
        "# Optimizer (include projection parameters)\n",
        "optim = RAdam(list(model.parameters()) + list(projection.parameters()), lr=config.lr)\n",
        "\n",
        "# Loss\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "\n",
        "# Number of epochs\n",
        "epochs = config.epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a32a0a2",
      "metadata": {},
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f6e6dbc",
      "metadata": {
        "cell_style": "center"
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook\n",
        "\n",
        "plt.ion()\n",
        "f, ax = plt.subplots(figsize=(4, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7cfb604",
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "exec(open('ultimate_cell_16_fix.py').read())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ad54561",
      "metadata": {},
      "source": [
        "### Plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16227252",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "idx = torch.randint(len(test_data), (4,))\n",
        "print(idx)\n",
        "\n",
        "inputs_embeds = test_data.encodings['inputs_embeds'][idx]\n",
        "labels = test_data.encodings['labels'][idx]\n",
        "mask_label = test_data.encodings['mask_label'][idx]\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Apply projection layer first\n",
        "    inputs_projected = projection(inputs_embeds.to(device).float())\n",
        "    sample_output = model(inputs_embeds=inputs_projected)\n",
        "\n",
        "for X, y, z, mask in zip(inputs_embeds.cpu(), sample_output.logits.cpu(), labels.cpu(), mask_label.cpu()):\n",
        "    f, ax = plt.subplots(1, 4, figsize=(15, 7.5), sharey=True, sharex=False)\n",
        "    f.tight_layout()\n",
        "    ax[0].imshow(X.detach().swapaxes(0, 1) - X.mean(dim=1), aspect=12, vmin=-1, vmax=1, cmap='seismic', \n",
        "                extent=[0, 20, 271*8/1000, 0])\n",
        "    ax[0].set_title(\"Input\", fontsize=14)\n",
        "    ax[0].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
        "    ax[0].set_xlabel(\"Offset Index\")\n",
        "    ax[0].set_yticks(np.arange(0, 2.5, 0.5))\n",
        "    ax[0].yaxis.set_minor_locator(AutoMinorLocator(2))\n",
        "    ax[0].set_ylabel(\"t (s)\")\n",
        "    \n",
        "    output = y\n",
        "    ax[1].imshow(output.detach().swapaxes(0, 1) - output.mean(), aspect=12, vmin=-1, vmax=1, cmap='seismic',\n",
        "                extent=[0, 20, 271*8/1000, 0])\n",
        "    ax[1].set_title(\"Reconstructed\", fontsize=14)\n",
        "    ax[1].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
        "    ax[1].set_xlabel(\"Offset Index\")\n",
        "    \n",
        "    ax[2].imshow(z.detach().swapaxes(0, 1) - z.mean(), aspect=12, vmin=-1, vmax=1, cmap='seismic',\n",
        "                extent=[0, 20, 271*8/1000, 0])\n",
        "    ax[2].set_title(\"Label\", fontsize=14)\n",
        "    ax[2].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
        "    ax[2].set_xlabel(\"Offset Index\")\n",
        "    \n",
        "    diff = 10 * (z - output)\n",
        "    im4 = ax[3].imshow(diff.detach().swapaxes(0, 1), aspect=12, vmin=-1, vmax=1, cmap='seismic',\n",
        "                      extent=[0, 20, 271*8/1000, 0])\n",
        "    ax[3].set_title(\"10 x (Label - Reconstructed)\", fontsize=14)\n",
        "    ax[3].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
        "    ax[3].set_xlabel(\"Offset Index\")\n",
        "    plt.ylim(2.01, 0)\n",
        "        \n",
        "    cbar_ax = f.add_axes([1, 0.255, 0.0125, 0.52])\n",
        "    cbar = f.colorbar(im4, cax=cbar_ax)\n",
        "    cbar.set_ticks(np.arange(-1, 1.25, .25))\n",
        "    cbar.set_ticklabels([-1, \"\", \"\", \"\", \"\", \"\", \"\", \"\", 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfcbe401",
      "metadata": {},
      "source": [
        "## Finalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00712ca8",
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Save everything\n",
        "print(\"Saving to\", config.parent_dir)\n",
        "if os.path.exists(os.path.join(config.parent_dir, 'model.pt')):\n",
        "    if input(\"Path exists. Overwrite? (y/n)\") == 'y':\n",
        "        torch.save(model, os.path.join(config.parent_dir, 'model.pt'))\n",
        "        avg_train_loss_arr = np.array(avg_train_loss)\n",
        "        avg_valid_loss_arr = np.array(avg_valid_loss)\n",
        "        np.save(os.path.join(config.parent_dir, 'train_loss.npy'), avg_train_loss_arr)\n",
        "        np.save(os.path.join(config.parent_dir, 'valid_loss.npy'), avg_valid_loss_arr)\n",
        "        torch.save(config, os.path.join(config.parent_dir, 'config.pt'))\n",
        "        print(\"Saved successfully to\", config.parent_dir)\n",
        "    else:\n",
        "        print(\"Saving failed.\")\n",
        "else:\n",
        "    torch.save(model, os.path.join(config.parent_dir, 'model.pt'))\n",
        "    avg_train_loss_arr = np.array(avg_train_loss)\n",
        "    avg_valid_loss_arr = np.array(avg_valid_loss)\n",
        "    np.save(os.path.join(config.parent_dir, 'train_loss.npy'), avg_train_loss_arr)\n",
        "    np.save(os.path.join(config.parent_dir, 'valid_loss.npy'), avg_valid_loss_arr)\n",
        "    torch.save(config, os.path.join(config.parent_dir, 'config.pt'))\n",
        "    print(\"Saved successfully to\", config.parent_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a04b2b6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "idx = torch.randint(len(test_data), (4,))\n",
        "print(idx)\n",
        "\n",
        "inputs_embeds = test_data.encodings['inputs_embeds'][idx]\n",
        "labels = test_data.encodings['labels'][idx]\n",
        "mask_label = test_data.encodings['mask_label'][idx]\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Apply projection layer first\n",
        "    inputs_projected = projection(inputs_embeds.to(device).float())\n",
        "    sample_output = model(inputs_embeds=inputs_projected)\n",
        "\n",
        "for X, y, z, mask in zip(inputs_embeds.cpu(), sample_output.logits.cpu(), labels.cpu(), mask_label.cpu()):\n",
        "    f, ax = plt.subplots(1, 4, figsize=(15, 7.5), sharey=True, sharex=False)\n",
        "    f.tight_layout()\n",
        "    ax[0].imshow(X.detach().swapaxes(0, 1) - X.mean(dim=1), aspect=12, vmin=-1, vmax=1, cmap='seismic', \n",
        "                extent=[0, 20, 271*8/1000, 0])\n",
        "    ax[0].set_title(\"Input\", fontsize=14)\n",
        "    ax[0].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
        "    ax[0].set_xlabel(\"Offset Index\")\n",
        "    ax[0].set_yticks(np.arange(0, 2.5, 0.5))\n",
        "    ax[0].yaxis.set_minor_locator(AutoMinorLocator(2))\n",
        "    ax[0].set_ylabel(\"t (s)\")\n",
        "    \n",
        "    output = y\n",
        "    ax[1].imshow(output.detach().swapaxes(0, 1) - output.mean(), aspect=12, vmin=-1, vmax=1, cmap='seismic',\n",
        "                extent=[0, 20, 271*8/1000, 0])\n",
        "    ax[1].set_title(\"Reconstructed\", fontsize=14)\n",
        "    ax[1].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
        "    ax[1].set_xlabel(\"Offset Index\")\n",
        "    \n",
        "    ax[2].imshow(z.detach().swapaxes(0, 1) - z.mean(), aspect=12, vmin=-1, vmax=1, cmap='seismic',\n",
        "                extent=[0, 20, 271*8/1000, 0])\n",
        "    ax[2].set_title(\"Label\", fontsize=14)\n",
        "    ax[2].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
        "    ax[2].set_xlabel(\"Offset Index\")\n",
        "    \n",
        "    diff = 10 * (z - output)\n",
        "    im4 = ax[3].imshow(diff.detach().swapaxes(0, 1), aspect=12, vmin=-1, vmax=1, cmap='seismic',\n",
        "                      extent=[0, 20, 271*8/1000, 0])\n",
        "    ax[3].set_title(\"10 x (Label - Reconstructed)\", fontsize=14)\n",
        "    ax[3].xaxis.set_minor_locator(AutoMinorLocator(5))\n",
        "    ax[3].set_xlabel(\"Offset Index\")\n",
        "    plt.ylim(2.01, 0)\n",
        "        \n",
        "    cbar_ax = f.add_axes([1, 0.255, 0.0125, 0.52])\n",
        "    cbar = f.colorbar(im4, cax=cbar_ax)\n",
        "    cbar.set_ticks(np.arange(-1, 1.25, .25))\n",
        "    cbar.set_ticklabels([-1, \"\", \"\", \"\", \"\", \"\", \"\", \"\", 1])\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22b39c54",
      "metadata": {},
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a623cf1a",
      "metadata": {},
      "source": [
        "Devlin, J., M.-W. Chang, K. Lee, and K. Toutanova, 2018, Bert: Pre-training of deep bidirectional transformers for language understanding: arXiv preprint arXiv:1810.04805.\n",
        "\n",
        "Harsuko, R., and T. Alkhalifah, 2022, Storseismic: An approach to pre-train a neural network to store seismic data features: 83rd EAGE Annual Conference & Exhibition, European Association of Geoscientists & Engineers, 1â€“5.\n",
        "\n",
        "Xiong, R., Yang, Y., He, D., Zheng, K., Zheng, S., Xing, C., Zhang, H., Lan, Y., Wang, L. and Liu, T., 2020, November. On layer normalization in the transformer architecture. In International Conference on Machine Learning (pp. 10524-10533). PMLR."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "storseismic",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}